---
title: "INSERT A GOOD TITLE HERE"
output:
  bookdown::html_document2: default
  bookdown::pdf_document2: default
---

**INTRODUCTION**  
- ecology of games  
- network management  
- case of sea level rise  

**BACKGROUND**  
- sea level rise as general problem  
- sea level rise in case of Bay Area  
- regional governance efforts  

**RATIONALE**  
- governance as a multi-actor situation without formal hierarchy, instead largely horizontal approaches to steering and decision-making (e..g, Klijn et a. 2010).  
- theory about network management (klijn/edelenbos, provan/kenis), EG framework (Lubell, Berardo), perhaps a little ACF  
- preferred management strategies and policy tools as a function of the portfolio of issues someone is concerned about  
- research questions:  


```{r startup_code, echo = F,message=F,results='hide',warning=F}
RERUN_MLTA = FALSE
seed = 24

packs =c('tidyverse','purrr','data.table','statnet','latentnet','bipartite','lvm4net','Ternary',
         'ggthemes','here','ggnetwork','gridExtra','ggrepel','corrplot','htmlTable','readxl','nFactors')
need = packs[!packs %in% names(installed.packages()[,2])]
invisible(sapply(need,function(x) suppressMessages(install.packages(x,type= 'source'))))
invisible(sapply(packs,function(x) suppressMessages(library(x,character.only = T))))

old = theme_set(theme_bw())
orig = readxl::read_excel('input/SLRSurvey_Full.xlsx')
orig$Q4[is.na(orig$Q4)]<-'Other'
#recode anything with fewer than 10 respondents as other
# see what wed recode
#as.data.table(table(orig$Q4))[order(-N),][N<10,]
orig$Q4[orig$Q4 %in% as.data.table(table(orig$Q4))[order(-N),][N<10,]$V1] <- 'Other'
orig$Q4[grepl('Other',orig$Q4)]<-'Other'
incidence_dt = fread("CurrentFiles/Data/AdjMatrix_MinOtherRecode.csv")

incidence_mat = as.matrix(incidence_dt[,-c('ResponseId','DK')])
rownames(incidence_mat)<-incidence_dt$ResponseId
#drop isolates
incidence_mat = incidence_mat[rowSums(incidence_mat)!=0,]
incidence_mat = incidence_mat[,!grepl('Other',colnames(incidence_mat))]

#create network object
bip_net = as.network(incidence_mat,matrix.type = 'incidence',bipartite = T,directed = F,loops = F)
#code actor types
bip_net %v% 'Actor_Type' <- orig$Q4[match(network.vertex.names(bip_net),orig$ResponseId)]
#code concept types
concept_types = fread('input/Combined_VectorTypes_NoNewOther.csv')
bip_net %v% 'Concept_Type' <- concept_types$Type[match(network.vertex.names(bip_net), concept_types$Vector)]
set.vertex.attribute(bip_net,'Concept_Type',value = 'Person',v = which(is.na(bip_net %v% 'Concept_Type')))

bip_net %v% 'id' <- network.vertex.names(bip_net)
bip_net %v% 'id_concept' <- ifelse({bip_net %v% 'Concept_Type'} == 'Person',network.vertex.names(bip_net),bip_net %v% 'Concept_Type')

bip_net %v% 'b1_dummy_b2_names' <- ifelse({bip_net %v% 'Concept_Type'} == 'Person','Person',bip_net %v% 'vertex.names')
#convert to incidence matrix
Y = as.sociomatrix(bip_net)
Y = Y[,!grepl('Other',colnames(Y))]
Y<-Y[,sort(colnames(Y))]
```

  
**METHODS AND MATERIALS**  

**Data**  
- survey design and implementation  
- response statistics (sample, response rate, etc.)  
- basic survey descriptives  
  - summary table of actor train responses (experience, org type, etc.)  
  - three panel plot bar plot of frequency of choices for each of concerns, barriers, policies  
Figure \@ref(fig:figure-choice-percentages) shows the percentage of respondents who selected each item.

```{r figure-choice-percentages, echo = F,message = F,warning = F,fig.cap = 'Frequency of response choices in sample'}

mY = melt(Y)
mY$cat = {bip_net %v% 'Concept_Type'}[match(mY$Var2,bip_net %v% 'vertex.names')]
mY<-data.table(mY)
mY = mY[,mean(value),by=.(Var2,cat)][order(-V1)]
mY$fact = fct_reorder(mY$Var2,mY$V1,mean)

#ideally this would be a fact_wrap call but getting factors to drop out takes some effort

grid.arrange(ggplot(mY[cat =='Concern',]) + geom_point(aes(x = fact,y = 100 * V1))+
               geom_text(aes(x = fact,y = 100 * V1 +5,label = fact),hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + 
  theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip(),
ggplot(mY[cat =='Barrier',]) + geom_point(aes(x = fact,y = 100 * V1))+
               geom_text(aes(x = fact,y = 100 * V1 +5,label = fact), hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + 
  theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip(),
ggplot(mY[cat =='Policy',]) + geom_point(aes(x = fact,y = 100 * V1))+
               geom_text(aes(x = fact,y = 100 * V1 +5,label = fact),hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + 
  theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip(),bottom= 'Respondent selection #',ncol = 3)

```
  
  

**Model**

Survey respondents identified up to three (each) from a range of issues, barriers, and strategies. Thus, each respondent is linked to between 0 and 9 system components. We are interested both in: (1) how actors in the governance network assort into different coalitions or preference groups; and (2) how different issues, barriers, and strategies assort into different "policy portfolios". To analyze both simultaneously, we use a *mixture of latent trait analyzers* (MLTA) (Gollini 2021) model. The MLTA model works like a combination of *latent class analysis* (LCA) and *latent trait analysis* (LTA). LCA is a clustering approach that identifies unobserved, underlying groups of respondents based upon observed responses. LTA is essentially a factor analysis for binary (or categorical) data--the goal being to represent respondents' choices for the `r ncol(Y)` concept options on a reduced set of underlying dimensions. In other words, LCA groups respondents and LTA groups responses.

An MLTA model does both--clustering of respondents and factoring of responses--at the same time. Observations are assumed to come from groups of respondents. Response choices (policies/concerns/barriers) are then assumed to be dependent upon group membership *and* a group-specific D-dimensional continuous latent trait variable. In other words, response variables are modeled as conditional on latent classes and latent traits. 

Responses are represented as a binary incidence matrix X~~nm, were *N* is the number of respondents and *M* is the # of response items. The number of classes and groups are preset prior to model fitting. We thus test the fit of models for range of group numbers (1 to 5, where G = 1 implies no subgroups) and trait dimensions (0 to 4, wherein a 0 dimension MLTA is identical to an LCA). 

```{r mlta_analysis,echo = F,message=F,results='hide',warning=F,results = 'hide'}
#### note -- mlta takes vectors instead of single D and G values -- but pblapply is used to parallelize #####
###DO NOT RUN FULL VERSION EXCEPT ON A FANCY COMPUTER WHEN YOU HAVE A LOT OF TIME -- HIGH DIMENSION MODELS TAKE FOREVER.....
### CURRENTLY RERUN_MLTA is set to false, so this chunk loads an rds file from an old fit ###
D = 2
G = 3
max_dims = 2
max_groups = 3
opts = data.table(expand.grid(D = 0:max_dims,G = 1:max_groups,fix = c(F,T)))
opts = opts[D>0|!fix,]
### this part takes a while, so I commented out and upload an RDS at the end ###
if(RERUN_MLTA){
require(doParallel)
cluster = makeCluster(4)
registerDoParallel(cluster)
clusterExport(cl = cluster,varlist = list('opts','Y'))
clusterEvalQ(cl = cluster,require(lvm4net))
mlta_tests = foreach(i = 1:nrow(opts)) %dopar% {mlta(X = Y, D = opts$D[i], G = opts$G[i],wfix = opts$fix[i],nstarts = 5,maxiter = 1e3)}
saveRDS(mlta_tests,'temp_objects/mlta_results.rds')
}
```

**Model Fit**
```{r mlta_results,warning=F,echo = F,message = F}
mlta_temp = readRDS('temp_objects/mlta_results.rds')
mlta_results = data.table(opts,BIC = sapply(mlta_temp,function(x) x$BIC))
mlta_results$G_fix = paste0('G = ',mlta_results$G,' (fixed slope = ',mlta_results$fix,')')
mlta_results$BIC <- round(mlta_results$BIC)
mlta_cast = dcast(mlta_results[order(BIC)],G_fix ~ D,value.var = 'BIC')
```


```{r tables-mlta_gof,echo = F,message = F,warning = F}
htmlTable(mlta_cast[,-1],caption = 'BIC scores by MLTA specification',rnames = mlta_cast$G_fix,header = paste0('D = ',0:max_dims),
          tfoot = '*fixed slope refers to whether slope is constant across all groups or group-specific')
```

Table \@ref(tab:mlta_results) shows Bayesian information criterion (BIC) goodness-of-fit scores for MLTAs fit to different combinations of group and dimension numbers and with slopes either fixed or varied across all subgroups.^[Briefly, slope parameters reflect within-group (for fixed slope = FALSE) or overall (for fixed slope = TRUE) heterogeneity for a given response variable--large slope parameters reflect larger differences in the probability of response between group members. Slope parameters also reflect interdependence between responses--two positive slopes mean that two items have a simultaneous probability of selection greater than the group median more often than would be expected if the items are locally independent (Gollini and Murphy 2014).]. The simplest, most restrictive model--no subgroups, no underlying trait dimension--is the most parsimonious. However, given the prevalance of several common responses shown in figure \@ref(fig:figure_choice_percentages), it is unsurprising that the single-cluster model performs fairly well. These broadly shared concerns and preferences, such as recognition that sea level rise poses problems for transportation and stormwater and belief that a SLR plan is needed, are associated with a more diverse array of secondary concerns and policy responses that can be teased out with a multidimensional model. Moreover, overall goodness-of-fit scores are fairly similar across specifications, particularly for fixed slope models where slope parameters are assumed to be constant across groups. Because we are interested in underlying differences among network subgroups, we perform a further series of factor analysis and cluster analysis methods to identify suitable values of *D* (underlying trait dimensions) and *G* (number of subgroups) for subsequent analysis.

*Identifying underlying trait dimensions*

As described above, an LTA model is essentially a factor analysis--thus, we can use typical factor analysis tools for identifying an appropriate number of dimensions. Figure \@ref(fig:figure_factor_analysis) plots Eigen values by factor number along with a series of non-graphical tests meant to identify an optimal number of factors. These tests are not all in agreement, ranging from a recommendation of 2 factors (the statistical "elbow" of the curve) to 17 (the number of factors with an Eigenvalue greater than 1). For parsimony, we select the lowest recommended value, *D* = 2, and fit an MLTA model with two underlying trait dimensions.

```{r figure_factor_analysis, echo = F,message = F,warning = F}
ev <- eigen(cor(Y)) # get eigenvalues
ap <- nFactors::parallel(subject=nrow(Y),var=ncol(Y),
  rep=100,cent=.05)

nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS,xlab = 'Factors',main = 'Scree plot of factor Eigenvalues')
```



*Identifying subgroups*

We take a similar approach to identifying an appropriate number of groups. Figure \@ref(fig:figure_k_means) hierarchically presents a series of k-means clustering results fit to different values of *k*. The top level shows a single cluster model (i.e., no subgroups), and the very bottom layer shows groups for *k* = 10. The arrows in figure \@ref(fig:figure_k_means) show how respondents change groupings as the number of clusters changes. At high k-values, we observe that the clusters are unstable--respondents who were grouped into separate clusters at lower k-values are now mixed up into totally new groupings. In this regard, *k* = 3 appears to be a good cluster value--at *k* = 4, clusters become less stable, while *k* = 2 appears to mask a distinction between two underlying subgroups.

```{r figure_k_means, echo = F,message = F,warning = F}
set.seed(24)
library(clustree)

k_vals = 1:10
tmp <- NULL
for (k in k_vals){
  tmp[k] <- kmeans(Y, k, nstart = 30)
}
df <- data.frame(tmp)
# add a prefix to the column names
colnames(df) <- k_vals
colnames(df) <- paste0("k",colnames(df))
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
ind.coord <- df.pca$x
ind.coord <- ind.coord[,1:2]
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))
clustree(df, prefix = "k")

```

```{r message=F,warning=F,echo = F}
index2 = which(opts$D==D&opts$G==G&opts$fix==T)
group_probs = mlta_temp[[index2]]$z
gp = data.table(group_probs)
```

Given the results presented above, we fit a final MLTA model with *G* = 3 and *D* = 2, keeping item-response slopes fixed across subgroups. Using this model, figure \@ref(fig:figure_group_probability_map) shows the predicted probability of group membership. The total probability must sum to one. Most respondents have a very high probability of being in a single group, with a just a limited amount showing a more ambiguous prediction. Taking the highest probability for each respondent (across all three groups), the median maximum probability is `r round(median(apply(gp,1,max)),2)`, and the minimum is `r round(min(apply(gp,1,max)),2)`.


```{r figure_group_probability_map, echo=F, message=FALSE, warning=FALSE}
TernaryPlot(alab = "p(Group 1) \u2192", blab = "p(Group 2) \u2192", clab = "\u2190 p(Group 3)",
            point = 'up',atip = 'G1', btip = 'G2',ctip = 'G3',
            lab.col = c('red', 'darkgreen', 'blue'), tip.col = c('red','darkgreen','blue'),
            lab.cex = 0.8, grid.minor.lines = 0,
            grid.lty = 'solid', col = rgb(0.9, 0.9, 0.9), grid.col = 'white', 
            axis.col = rgb(0.6, 0.6, 0.6), ticks.col = rgb(0.6, 0.6, 0.6),
            axis.rotate = FALSE,
            padding = 0.08)
AddToTernary(points, coordinates = gp, pch = 21, cex = 1)
```


Just as respondents are clustered within groups, concepts are linked to underlying trait dimensions. We can plot the strength of these linkages by plotting the slopes for the logistic response functions--these are interpreted similarly to loadings in a factor analysis, in that a slope near 1 or -1 indicates a strong relationship between the variable and the underlying trait dimension, and a loading near 0 indicates a weak relationship.
```{r figure_factor_loadings, warning = F,message = F,echo = F,fig.height=5,fig.width = 5}
mod = mlta_temp[[index2]]

beta_dt = data.table(t(mod$w),item = colnames(Y))
beta_dt$group = concept_types$Type[match(beta_dt$item,concept_types$Vector)]
circles <- data.frame( x0 = 0, y0 = 0, r = 1)

library(ggforce)
ggplot() +
      geom_circle(data = circles,aes(x0 = x0,y0 = y0,r = r),lty = 2, col = 'grey50') +
  geom_vline(xintercept = 0,lty = 2,col = 'grey40') +
  geom_hline(yintercept = 0,lty = 2,col = 'grey40') + 
geom_text_repel(data = beta_dt,aes(x = `Dim 1`,y = `Dim 2`,label = item,col = group,fill = group),
                size = 2.5,max.overlaps = 100,min.segment.length = 0.2,show.legend = F) +
    geom_point(data = beta_dt,aes(x = `Dim 1`,y = `Dim 2`,label = item,col = group,fill = group),
               pch = 19,show.legend = T) +
    scale_fill_colorblind(name = 'Concept type') +
  scale_color_colorblind(name = 'Concept type') +
  ggtitle('Slope estimates ("loadings") for item-response functions on latent traits') +
  theme_bw() + 
  scale_x_continuous(name= 'Slope for dimension 1',limits = c(-1,1)) + 
  scale_y_continuous(name= 'Slope for dimension 2',limits = c(-1,1)) + 

  theme(axis.title = element_text(size = 10,inherit.blank = F,family = 'Times',,margin =c(1,1,1,1)),
        legend.position = c(0.9,0.2)) 


```



**RESULTS**  
**Correlation between external items and concept responses**  
**Core differences between groups**  
```{r echo = F,warning = F, message = F}

require(ggradar)
Y_dat = data.table(Y)
Y_dat$group =  apply(mod$z,1,which.max)

Ydt = melt(Y_dat,id.vars = 'group')
Ydt$item_type = concept_types$Type[match(Ydt$variable,concept_types$Vector)]

Y_means = Ydt[,mean(value),by=.(group,variable,item_type)]
Y_means$group = paste0('Group ',Y_means$group)
radar_grobs = lapply(unique(Ydt$item_type),function(x) {
  tmp = dcast(Y_means[item_type == x,],group ~ variable,value.var = 'V1')
  ggradar(tmp,axis.label.size = 3,group.point.size = 1) +ggtitle(x) +
    theme(plot.margin = unit(rep(0.1,4),units = 'cm'))
  })
op <- par(mar = c(.1, .1, .1, .1))
radar_grobs[[1]]
radar_grobs[[2]]
radar_grobs[[3]]
```

**more results**  

```{r echo = F,warning = F, message = F}
require(networkD3)

# Load energy projection data
URL <- "https://cdn.rawgit.com/christophergandrud/networkD3/master/JSONdata/energy.json"

test= Ydt[,sum(value),by=.(item_type,group,variable)][item_type%in%c('Concern','Policy'),][group == 1,]
devtools::install_github('Displayr/flipPlots')
library(flipPlots)
SankeyDiagram(test,
              link.color = "Source", 
              weights = my.data$freq) 

install.packages('flipPlots')

Ydt[,sum(value),by=.(item_type,group,variable)][item_type=='Concern'&group == 1,]

Ydt[,sum(value),by=.(item_type,group,variable)][item_type=='Policy'&group == 1,]

sankey_list = list()
sankey_list$nodes <- data.frame(name = unique(Ydt$variable[Ydt$item_type %in% c('Concern','Policy')]))




str(Energy)



```


**DISCUSSION**


**CONCLUSION**






